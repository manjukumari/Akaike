{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28a97aa5",
   "metadata": {},
   "source": [
    "# Computer Vision Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9541de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing openCv both as cv2 and cv for better convinence \n",
    "import cv2  \n",
    "import cv2 as cv \n",
    "\n",
    "# Importing numpy for working with numpy arrays\n",
    "import numpy as np \n",
    "\n",
    "# Importing pyplot as plt from maplotlib for Image Visualization\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "#Collab not support cv2.imshow method thus, importing cv2.imshow method for better Image visualization \n",
    "#from google.colab.patches import cv2_imshow  \n",
    "\n",
    "#Importing PIL library for working with Images\n",
    "from PIL import Image \n",
    "\n",
    "#Importing asarray method from numpy for dealing with pixels of Images\n",
    "from numpy import asarray \n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "#Importing ndimage from scipy as this package contains various functions for multidimensional image processing.\n",
    "from scipy import ndimage\n",
    "\n",
    "#Importing filters, features, measures and color from skimage\n",
    "from skimage import filters, feature, measure, color\n",
    "\n",
    "#Importing Watershed for touching Grains sepration\n",
    "from skimage.segmentation import watershed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c867f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining show function for displaying  image with custom X and Y cordinates\n",
    "\n",
    "def show(image,x=30,y=7):\n",
    "  img=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "  plt.figure(figsize=(x,y))\n",
    "  plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffb0a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Image\n",
    "img = cv2.imread(\"/content/drive/MyDrive/Aman's_Akaike Assignment/CV_SOLUCTION/data/test/image_1.jpg\")\n",
    "\n",
    "#Using predefined show function for displaying the image\n",
    "show(img,25,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb15b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting Image BGR Image to Gray for Image thresholding and further Image-Preprocessing application\n",
    "grayscale_Image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh_img = cv2.threshold(grayscale_Image, 120, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "#Using show function earlier defined\n",
    "show(thresh_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4754292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise removal\n",
    "kernel = np.ones((3),np.uint8)\n",
    "clear_image = cv2.morphologyEx(thresh_img,cv2.MORPH_OPEN, kernel, iterations=8)\n",
    "\n",
    "#Using show function earlier defined\n",
    "show(clear_image)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec955692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copying the preprocessed image as label_image\n",
    "label_image = clear_image.copy()\n",
    "\n",
    "#Creating a label_count variable to the count the number of grains in the image\n",
    "label_count = 0\n",
    "\n",
    "#Shape function for getting height and width\n",
    "rows, cols = label_image.shape\n",
    "\n",
    "#Looping through the pixel of image using rows and column of image\n",
    "for j in range(rows):\n",
    "    for i in range(cols):\n",
    "        pixel = label_image[j, i]\n",
    "\n",
    "        #Here there is single channel with 2 pixel intensities, Either 0 or 255. 0 represent black portion, where 255 represent grains (White).\n",
    "        #Counting the total number of pixel with intensity 255\n",
    "        if 255 == pixel:\n",
    "            label_count += 1\n",
    "\n",
    "            ##Applying floodFill method of opencv which will help in filling the backgroud that will ultimately helps in couting the contoured grain easily\n",
    "            cv.floodFill(label_image, None, (i, j), label_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572b28cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of foreground objects\", label_count)\n",
    "show(label_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd28b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Countours method to get the count of rice grains\n",
    "contours, hierarchy = cv.findContours(clear_image, \n",
    "                                      cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "output_contour = cv.cvtColor(clear_image, cv.COLOR_GRAY2BGR)\n",
    "cv.drawContours(output_contour, contours, -1, (0, 0, 255), 2)\n",
    "print(\"Number of detected contours\", len(contours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e387a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2_imshow(output_contour)\n",
    "\n",
    "print(\" \\n Number of detected contours\", len(contours))\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92ca81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To visualize the segmentation conveniently, There needed a colour-code the labelled regions using the color, thus I did it.\n",
    "\n",
    "\n",
    "#Applying  distance_transform_edt to computes the distance from non-zero (i.e. non-background) points to the nearest zero (i.e. background) point.\n",
    "dist_trans = ndimage.distance_transform_edt(clear_image)\n",
    "\n",
    "#Applying peak_local_max function for getting coordinates of local peaks (maxima) in an image.\n",
    "local_max = feature.peak_local_max(dist_trans, min_distance=23)\n",
    "\n",
    "\n",
    "local_max_mask = np.zeros(dist_trans.shape, dtype=bool)\n",
    "local_max_mask[tuple(local_max.T)] = True\n",
    "\n",
    "#Aplying Watershed algorithm\n",
    "labels = watershed(-dist_trans, measure.label(local_max_mask), mask=clear_image) # separate merged corns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b1cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label2rgb function, specifying the background label with argument bg_label=0.\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.imshow(color.label2rgb(labels, bg_label=0))\n",
    "print(\"Number of Rice grains are : %d\" % labels.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdd8636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating A list name count for counting the total Broken rice grains\n",
    "count = []\n",
    "\n",
    "#Iterating through contour and filtering out the rice grains with area less than 800 and then appending to the count variable.\n",
    "for x in contours:\n",
    "\n",
    "  #Using contourArea method to get the area of rice (Contour)\n",
    "  area = cv.contourArea(x)\n",
    "  if area < 800 :\n",
    "    count.append(x)\n",
    "\n",
    "#Output of the count list.\n",
    "\n",
    "print(\"Total number of broken rice present in the Image is: \",len(count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
